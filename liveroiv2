import cv2
import mediapipe as mp
import numpy as np

mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

cap = cv2.VideoCapture(0)

clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))

with mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=1,
    min_detection_confidence=0.7,
    min_tracking_confidence=0.7
) as hands:

    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            continue

        frame = cv2.flip(frame, 1)
        clean_frame = frame.copy()
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        result = hands.process(rgb)

        roi = None
        roi_processed = None

        if result.multi_hand_landmarks:
            for idx, hand_landmarks in enumerate(result.multi_hand_landmarks): 
                hand_label = "Unknown"
                if result.multi_handedness:
                    hand_label = result.multi_handedness[idx].classification[0].label

                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                h, w, _ = frame.shape

                # --- Get Keypoints ---
                wrist = np.array([hand_landmarks.landmark[0].x, hand_landmarks.landmark[0].y])
                index_base = np.array([hand_landmarks.landmark[5].x, hand_landmarks.landmark[5].y])
                pinky_base = np.array([hand_landmarks.landmark[17].x, hand_landmarks.landmark[17].y])

                # --- Compute palm normal for palm/back side classification ---
                v1 = index_base - wrist
                v2 = pinky_base - wrist
                normal = np.cross(np.append(v1, 0), np.append(v2, 0))
                normal /= np.linalg.norm(normal) + 1e-6

                if hand_label == "Left":
                    normal = -normal

                side = "Palm Side" if normal[2] > 0 else "Back Side"
                cv2.putText(frame, f"{hand_label}: {side}", (30, 50),
                            cv2.FONT_HERSHEY_SIMPLEX, 1,
                            (0, 255, 0) if side == "Palm Side" else (0, 0, 255), 2)

                if side != "Palm Side":
                    continue

                # --- Convert to pixel coordinates ---
                def to_xy(lm):
                    return np.array([int(lm[0] * w), int(lm[1] * h)], dtype=np.int32)

                wrist_xy = to_xy(wrist)
                index_base_xy = to_xy(index_base)
                pinky_base_xy = to_xy(pinky_base)

                # --- ROI geometry ---
                base_vec = pinky_base_xy - index_base_xy
                mid_top = (index_base_xy + pinky_base_xy) / 2
                down_vec = wrist_xy - mid_top

                # Orthogonal downward vector
                perp_vec = down_vec - (np.dot(down_vec, base_vec) / np.dot(base_vec, base_vec)) * base_vec
                perp_unit = perp_vec / (np.linalg.norm(perp_vec) + 1e-6)
                base_unit = base_vec / (np.linalg.norm(base_vec) + 1e-6)
                roi_size = int(np.linalg.norm(base_vec))

                # âœ… Automatically correct orientation to always point toward wrist
                if np.dot(wrist_xy - mid_top, perp_unit) < 0:
                    perp_unit = -perp_unit

                # --- ROI corners ---
                top_left = index_base_xy
                top_right = pinky_base_xy
                bottom_right = (pinky_base_xy + perp_unit * roi_size).astype(int)
                bottom_left = (index_base_xy + perp_unit * roi_size).astype(int)
                pts = np.array([top_left, top_right, bottom_right, bottom_left], np.int32).reshape((-1, 1, 2))
                cv2.polylines(frame, [pts], isClosed=True, color=(255, 0, 0), thickness=2)

                # --- Orientation normalization ---
                angle = np.degrees(np.arctan2(base_unit[1], base_unit[0]))
                center = (int(mid_top[0]), int(mid_top[1]))
                rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)

                # Flip the rotation angle for left hand to keep upright
                if hand_label == "Left":
                    rotation_matrix = cv2.getRotationMatrix2D(center, angle + 180, 1.0)

                rotated = cv2.warpAffine(clean_frame, rotation_matrix, (w, h))

                # Transform ROI coordinates after rotation
                pts_rotated = cv2.transform(pts, rotation_matrix)

                # --- Crop ROI ---
                x_min, y_min = np.min(pts_rotated[:, 0, :], axis=0)
                x_max, y_max = np.max(pts_rotated[:, 0, :], axis=0)
                x_min, y_min = np.clip([x_min, y_min], 0, [w - 1, h - 1])
                x_max, y_max = np.clip([x_max, y_max], 0, [w - 1, h - 1])

                if x_max > x_min and y_max > y_min:
                    roi = rotated[int(y_min):int(y_max), int(x_min):int(x_max)]

                    if roi.size > 0:
                        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
                        blur = cv2.GaussianBlur(gray, (5, 5), 0)
                        roi_processed = clahe.apply(blur)
                        roi_processed = cv2.resize(roi_processed, (256, 256))

                        # Flip left-hand ROI horizontally for consistency
                        if hand_label == "Left":
                            roi_processed = cv2.flip(roi_processed, 1)

        # --- Display windows ---
        cv2.imshow("Camera Feed", frame)
        if roi is not None:
            cv2.imshow("Palm ROI (Raw)", roi)
        if roi_processed is not None:
            cv2.imshow("Palm ROI (Normalized)", roi_processed)

        if cv2.waitKey(5) & 0xFF == 27:
            break

cap.release()
cv2.destroyAllWindows()
